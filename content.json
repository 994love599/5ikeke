{"meta":{"title":"�����ũ","subtitle":"","description":"","author":"yuhang","url":"https://www.5ikeke.xyz","root":"/"},"pages":[{"title":"博主简介","date":"2020-02-16T07:23:43.603Z","updated":"2020-02-16T07:23:43.603Z","comments":true,"path":"about/index.html","permalink":"https://www.5ikeke.xyz/about/index.html","excerpt":"","text":"姓名：王航性别：男出生年月：1996年7月毕业院校：本科/北京邮电大学世纪学院专业：计算机科学与技术工作年限：2年技术博客：http://5ijava.xyz/Github：https://github.com/994love599期望职位：Java中级程序员，web前后端期望薪资：税前月薪15k~20k期望城市：北京联系方式手机：18518163797（非诚勿扰）Email：804255523@QQ.comWechat：wh804255523工作经历亿阳信通股份有限公司北京分公司 （ 2018年7月 ~ 至今 ）所在部门：新产品预研部 应用组电信IDC/ISP信息安全管理系统电信“IDC/ISP 信息安全管理系统”日常维护、Bug修改电信“IDC/ISP 信息安全管理系统”子功能“日志溯源”改造开发电信“IDC/ISP 信息安全管理系统”子功能“策略可视化”的设计开发电信“IDC/ISP 信息安全管理系统”子功能“IP+域名白名单管理”开发电信“IDC/ISP 信息安全管理系统”web部分的IPV6 改造。电信“IDC/ISP 信息安全管理系统”子功能的权限分离改造。电信“IDC/ISP 信息安全管理系统”与电信 4A 系统的单点登录接口开发。电信“IDC/ISP 信息安全管理系统”自动化运维开发。电信“IDC/ISP 信息安全管理系统”的“IP 溯源”开发。电信“IDC/ISP 信息安全管理系统”的“基础数据深层次管控”功能开发。电信云资源系统日常维护、bug修改系统功能改造开发（老项目，接管改造）职业技能java基础扎实，有SpringBoot开发经验熟练使用 js、html、css、Ajax、vue.js、elementui等前端技术具备数据库设计开发能力：MySQL、Oracle、Redis、MongoDb熟练使用 Svn、Git、Maven、jenkins熟练使用Echarts部分功能，有数据可视化实操经验掌握Linux、nginx常用操作致谢感谢您花时间阅读我的简历，期待能有机会和您共事。欢迎关注微信公众号"},{"title":"友情链接","date":"2020-02-15T10:34:01.964Z","updated":"2020-02-15T10:34:01.964Z","comments":true,"path":"links/index.html","permalink":"https://www.5ikeke.xyz/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-02-15T08:49:48.430Z","updated":"2020-01-13T02:28:46.957Z","comments":false,"path":"tags/index.html","permalink":"https://www.5ikeke.xyz/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-01-13T07:19:39.080Z","updated":"2020-01-13T02:28:46.949Z","comments":false,"path":"categories/index.html","permalink":"https://www.5ikeke.xyz/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringBoot简单整合Kafka，实现消息发送与消费","slug":"a_1","date":"2020-02-15T14:42:03.000Z","updated":"2020-02-16T04:00:55.403Z","comments":true,"path":"2020/02/15/a_1/","link":"","permalink":"https://www.5ikeke.xyz/2020/02/15/a_1/","excerpt":"","text":"什么是kafkaKafka是一种发布-订阅模式的消息中间件当然，kafka的具体定义不再赘述，官方文档有详细讲解文档两份献上：官方文档 http://kafka.apache.org/中文文档 http://kafka.apachecn.org/话不多说，回归主题，直接上代码吧1、maven引入kafka依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt;2、在application.properties中完善kafka基础配置1234567891011121314151617181920#################### kafka配置 ##################### 指定kafka 代理地址，可以多个，以实际环境配置为准，我这里是本地localhost，9092端口spring.kafka.bootstrap-servers&#x3D;127.0.0.1:9092##生产者配置spring.kafka.producer.retries&#x3D;0# 每次批量发送消息的数量spring.kafka.producer.batch-size&#x3D;16384spring.kafka.producer.buffer-memory&#x3D;33554432# 指定消息key和消息体的编解码方式spring.kafka.producer.key-serializer&#x3D;org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer&#x3D;org.apache.kafka.common.serialization.StringSerializer##消费者配置# 指定默认消费者group idspring.kafka.consumer.group-id&#x3D;test-hello-groupspring.kafka.consumer.auto-offset-reset&#x3D;earliestspring.kafka.consumer.enable-auto-commit&#x3D;truespring.kafka.consumer.auto-commit-interval&#x3D;500# 指定消息key和消息体的编解码方式spring.kafka.consumer.key-deserializer&#x3D;org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer&#x3D;org.apache.kafka.common.serialization.StringDeserializer3、接下来开始实现 生产者的消息发送 以及 消费者的订阅我这里使用一个常量类，来配置topic：12345678public class kafkaConstants &#123; public final static String TOPIC_994=\"994\"; public final static String TOPIC_599=\"599\"; public final static String TOPIC_LXX=\"lxx\"; public final static String TOPIC_WYH=\"wyh\"; public final static String TOPIC_TEST1=\"test_1\"; public final static String TOPIC_TEST2=\"test_2\";&#125;生产者发送消息：123456789101112131415@Componentpublic class KfkaProducer &#123; private static Logger logger = LoggerFactory.getLogger(KfkaProducer.class); @Autowired private KafkaTemplate&lt;String, String&gt; kafkaTemplate; /** * @Description 发送消息 * @param topic 主题 * @param msgContent 消息内容 */ public void send(String topic,String msgContent) &#123; logger.info(\"###发送消息：topic=&#123;&#125; message = &#123;&#125;\",topic, msgContent); kafkaTemplate.send(topic, msgContent); &#125;&#125;这里使用KafkaTemplate来进行消息的发送，发送到主题topic，供消费者实时消费消费者消费：12345678910111213141516171819202122232425@Componentpublic class KafkaReceiver &#123; private static Logger logger = LoggerFactory.getLogger(KafkaReceiver.class); //定向消费 @KafkaListener(topics = &#123;\"599\"&#125;) public void listen_1(ConsumerRecord&lt;?, ?&gt; record) &#123; Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value()); if (kafkaMessage.isPresent()) &#123; Object message = kafkaMessage.get(); logger.info(\"----------------- record =&#123;&#125;\",record); logger.info(\"------------------ message =\" + message); &#125; &#125; //动态消费 @KafkaListener(topicPattern = \"test.*\") public void listen_2(ConsumerRecord&lt;?, ?&gt; record) &#123; Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value()); if (kafkaMessage.isPresent()) &#123; Object message = kafkaMessage.get(); logger.info(\"----------------- record =&#123;&#125;\",record); logger.info(\"------------------ message =\" + message); &#125; &#125;&#125;对于消费者而言，可以定向的消费某一topic也可以动态消费某一系列topic上述方法中 listen_1 只消费 topic=“599”的消息listen_2 可消费 topic前缀为“test”的消息好了，写个接口测试下消息生产以及消费吧12345678910111213@RestControllerpublic class kafkaController &#123; @Autowired private KfkaProducer producer; private Gson gson = new GsonBuilder().create(); @RequestMapping(\"/testSendMsg\") @ResponseBody public String testSendMsg()&#123; String msg=\"您好呀，599\" producer.send(kafkaConstants.TOPIC_599,msg); return \"success\"; &#125;&#125;测试下接口：生产者发送消息成功，同时，消费者也消费成功公众号关注走一波，谢谢","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.5ikeke.xyz/categories/SpringBoot/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://www.5ikeke.xyz/tags/kafka/"}]},{"title":"推荐一名正在寻找坑位的设计师","slug":"a_2","date":"2020-02-14T13:13:14.000Z","updated":"2020-02-16T07:03:41.043Z","comments":true,"path":"2020/02/14/a_2/","link":"","permalink":"https://www.5ikeke.xyz/2020/02/14/a_2/","excerpt":"","text":"","categories":[{"name":"简历","slug":"简历","permalink":"https://www.5ikeke.xyz/categories/%E7%AE%80%E5%8E%86/"}],"tags":[{"name":"设计师","slug":"设计师","permalink":"https://www.5ikeke.xyz/tags/%E8%AE%BE%E8%AE%A1%E5%B8%88/"}]}]}